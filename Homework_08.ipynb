{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 08: Classification\n",
    "\n",
    "**Due:** Midnight on July 6th, BUT no late points will be charged if you get it in by the last late deadline. \n",
    "\n",
    "### Overview\n",
    "\n",
    "In this final homework before starting our course project, we will introduce the essential machine learning paradigm of **classification**. We will work with the **UCI Adult** dataset. This is a binary classification task.\n",
    "\n",
    "As we’ve discussed in this week’s lessons, the classification workflow is similar to what we’ve done for regression, with a few key differences:\n",
    "- We use `StratifiedKFold` instead of plain `KFold` so that every fold keeps the original class proportions.\n",
    "- We use classification metrics (e.g., accuracy, precision, recall, F1-score for binary classification) instead of regression metrics.\n",
    "- We could explore misclassified instances through a confusion matrix (though we will not do that in this homework).\n",
    "\n",
    "For this assignment, you’ll build a gradient boosting classification using `HistGradientBoostingClassifier` (HGBC) and explore ways of tuning the hyperparameters, including using the technique of early stopping, which basically avoiding have to tune the number of estimators (called `max_iter` in HGBC). \n",
    "\n",
    "HGBC has many advantages, which we explain below. \n",
    "\n",
    "\n",
    "### Grading\n",
    "\n",
    "There are 7 graded problems, each worth 7 points, and you get 1 point free if you complete the assignment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexa\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# General utilities\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import zipfile\n",
    "import requests\n",
    "from collections import Counter\n",
    "\n",
    "# Data handling and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display\n",
    " \n",
    "# Data source\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    " \n",
    "# scikit-learn core tools \n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    StratifiedKFold,\n",
    "    RandomizedSearchCV\n",
    ")\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    " \n",
    "# Import model \n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    " \n",
    "# Metrics\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    " \n",
    "# Distributions for random search\n",
    "from scipy.stats import loguniform, randint, uniform\n",
    "\n",
    "# pandas dtypes helpers\n",
    "from pandas.api.types import is_numeric_dtype, is_categorical_dtype\n",
    "from pandas import CategoricalDtype\n",
    "\n",
    "# Optuna Hyperparameter Search tool    (may need to be installed)\n",
    "import optuna\n",
    "\n",
    "\n",
    "# Misc\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "def format_hms(seconds):\n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(seconds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prelude 1: Load and Preprocess the UCI Adult Income Dataset\n",
    "\n",
    "- Load the dataset from sklearn\n",
    "- Preliminary EDA\n",
    "- Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype   \n",
      "---  ------          --------------  -----   \n",
      " 0   age             48842 non-null  int64   \n",
      " 1   workclass       46043 non-null  category\n",
      " 2   fnlwgt          48842 non-null  int64   \n",
      " 3   education       48842 non-null  category\n",
      " 4   education-num   48842 non-null  int64   \n",
      " 5   marital-status  48842 non-null  category\n",
      " 6   occupation      46033 non-null  category\n",
      " 7   relationship    48842 non-null  category\n",
      " 8   race            48842 non-null  category\n",
      " 9   sex             48842 non-null  category\n",
      " 10  capital-gain    48842 non-null  int64   \n",
      " 11  capital-loss    48842 non-null  int64   \n",
      " 12  hours-per-week  48842 non-null  int64   \n",
      " 13  native-country  47985 non-null  category\n",
      " 14  class           48842 non-null  category\n",
      "dtypes: category(9), int64(6)\n",
      "memory usage: 2.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Load and clean\n",
    "df = fetch_openml(name='adult', version=2, as_frame=True).frame\n",
    "\n",
    "df.replace(\"?\", np.nan, inplace=True)            # Some datasets use ? instead of Nan for missing data\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check: Is the dataset imbalanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "<=50K    0.760718\n",
      ">50K     0.239282\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['class'].value_counts(normalize=True))\n",
    "\n",
    "#imbalanced dataset is one which the classes you are trying to predict are not represented equally. Imbalanced datasets create biased learning, misleading metrics, and generalization issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YES:** It looks like this dataset is somewhat imbalanced. Therefore, we will \n",
    "1. Tell the model to compensate during training by setting `class_weight='balanced'` when defining the model;\n",
    "2. Evaluate it `balanced_accuracy` instead of `accuracy` and with class-aware metrics (precision, recall, F1); and\n",
    "3. [Optional] Adjust the probability threshold instead of relying on raw accuracy alone after examining the precision-recall trade-off you observe at 0.5.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Based on the considerations in **Appendix One**, we'll make the following changes to the dataset to facilitate training:\n",
    "\n",
    "\n",
    "1. Drop `fnlwgt` and `education`.   \n",
    "3. Replace `capital-gain` and `capital-loss` by their difference `capital_net` and add a log-scaled version `capital_net_log`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 13 columns):\n",
      " #   Column           Non-Null Count  Dtype   \n",
      "---  ------           --------------  -----   \n",
      " 0   age              48842 non-null  int64   \n",
      " 1   workclass        46043 non-null  category\n",
      " 2   education-num    48842 non-null  int64   \n",
      " 3   marital-status   48842 non-null  category\n",
      " 4   occupation       46033 non-null  category\n",
      " 5   relationship     48842 non-null  category\n",
      " 6   race             48842 non-null  category\n",
      " 7   sex              48842 non-null  category\n",
      " 8   hours-per-week   48842 non-null  int64   \n",
      " 9   native-country   47985 non-null  category\n",
      " 10  class            48842 non-null  category\n",
      " 11  capital_net      48842 non-null  int64   \n",
      " 12  capital_net_log  48842 non-null  float64 \n",
      "dtypes: category(8), float64(1), int64(4)\n",
      "memory usage: 2.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Drop the survey-weight column\n",
    "df_eng = df.drop(columns=[\"fnlwgt\"])\n",
    "\n",
    "# Keep only the ordinal education feature\n",
    "df_eng = df_eng.drop(columns=[\"education\"])      # retain 'education-num'\n",
    "\n",
    "# Combine capital gains and losses, add a log-scaled variant\n",
    "df_eng[\"capital_net\"]     = df_eng[\"capital-gain\"] - df_eng[\"capital-loss\"]\n",
    "df_eng[\"capital_net_log\"] = np.log1p(df_eng[\"capital_net\"].clip(lower=0))\n",
    "df_eng = df_eng.drop(columns=[\"capital-gain\", \"capital-loss\"])\n",
    "\n",
    "# check\n",
    "df_eng.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separate target and split\n",
    "\n",
    "Create the feature set `X` and the target set `y` (using `class` as the target) and split the dataset into 80% training and 20% testing sets, making sure to stratify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (39073, 12) (39073,)\n",
      "Test : (9769, 12) (9769,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df_eng.drop(columns=[\"class\"])\n",
    "y = (df_eng[\"class\"] == \">50K\").astype(int)\n",
    "\n",
    "# Split (with stratification)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=random_seed,\n",
    "    stratify=y                           # So same proportion of classes in train and test sets\n",
    ")\n",
    "\n",
    "#stratify parameter ensures taht your train and test sets ahve the same proportion of class labels (this is used to preserve class balance) if stratify=None it would be purely random sampling\n",
    "\n",
    "print(\"Train:\", X_train.shape, y_train.shape)\n",
    "print(\"Test :\", X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prelude 2: Create a data pipeline and the `HistGradientBoostingClassifier` model\n",
    "\n",
    "Histogram-based gradient boosting improves on the standard version by:\n",
    "\n",
    "* **Histogram splits:** bins each feature into ≤ `max_bins` quantiles (i.e., each bin is approximately the same size) and tests splits only between bins, slashing compute time and scaling to large data sets. Default for `max_bins` = 255. \n",
    "* **Native NaN handling:** treats missing values as their own bin—no imputation needed.\n",
    "* **Native Categorical Support**: accepts integer-encoded categories directly and tests “category c vs. all others” splits, eliminating one-hot blow-ups and fake orderings.\n",
    "* **Built-in early stopping:** stops training after no improvement in validation loss after `n_iter_no_change` rounds. `tol` defines \"improvement\" (default is 1e-7). \n",
    "* **Leaf shrinkage:** adds `l2_regularization`, which ridge-shrinks each leaf value (without changing tree shape) so tiny, noisy leaves have less effect.\n",
    "\n",
    ">**Summary:**  Histogram-based GB trades a tiny approximation error (binning) for a **huge speed-up** and adds extra conveniences, making it the preferred choice for large tabular data sets. Tuning workflow relies on **Early stopping** to stop training before overfitting occurs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a baseline model \n",
    "\n",
    "HGBC_model = HistGradientBoostingClassifier(\n",
    "    # tree structure and learning rate\n",
    "    learning_rate=0.1,            # These 5 parameters are at defaults for our baseline training in Problem 1              \n",
    "    max_leaf_nodes=31,            # but will be tuned by randomized search in Problem 2 and Optuna in Problem 3               \n",
    "    max_depth=None,               \n",
    "    min_samples_leaf=20,          \n",
    "    l2_regularization=0.0,        \n",
    "\n",
    "    # bins and iteration\n",
    "    max_bins=255,                 # default\n",
    "    max_iter=500,                 # high enough for early stopping\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=20,\n",
    "    validation_fraction=0.2,      # 20% monitored for early stopping\n",
    "    tol=1e-7,                     # default tolerance for validation improvement\n",
    "\n",
    "    # class imbalance\n",
    "    class_weight=\"balanced\",\n",
    "\n",
    "    random_state=random_seed,\n",
    "    verbose=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline appropriate for HGBC \n",
    "\n",
    "**Why use a `Pipeline` instead of encoding in the dataset first?**\n",
    "\n",
    "* **Avoid data leakage.** In each CV fold, the `OrdinalEncoder` is refit only on that fold’s training data, so the validation split never influences the encoder.\n",
    "* **Single, reusable object.** The pipeline bundles preprocessing + model, letting you call `fit`/`predict` on raw data anywhere (CV, Optuna, production) with identical behavior.\n",
    "* **Compatible with search tools.** `cross_validate`, `GridSearchCV`, and Optuna expect an estimator that can be cloned and refit; a pipeline meets that requirement automatically.\n",
    "\n",
    "Put simply, the pipeline gives you leak-free evaluation and portable, hassle-free tuning without extra code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\",   # Allow unseen categories during transform\n",
    "    unknown_value=-1,                     # Code for unseen categories\n",
    "    encoded_missing_value=-2,             # Code for missing values (NaN)\n",
    "    dtype=np.int64                        # Needed for HistGradientBoostingClassifier\n",
    ")\n",
    "\n",
    "#Notes:\n",
    "   #OrdinalEncoder is a tool to turn categorical (non-numeric) features into integers. The context here is that it will only perform to the 80% say the training set and the 20% is left out which is what we want.\n",
    "   #Because if you fit the encoder on the full dataset youd be using knowledge \n",
    "\n",
    "# Categorical features\n",
    "cat_cols = X.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "\n",
    "# Numeric features (everything that isn’t object / category)\n",
    "num_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    [(\"cat\", enc, cat_cols),\n",
    "     (\"num\", \"passthrough\", num_cols)]\n",
    ")\n",
    "\n",
    "pipelined_model = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"gb\",   HGBC_model)\n",
    "])\n",
    "\n",
    "#The pipeline is used to chain together a sequence of data transforms and final estimator into one object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Baseline Cross-Validation with F1\n",
    "\n",
    "In this problem, you will run a baseline cross-validation evaluation of your `HistGradientBoostingClassifier` pipeline, using `HGBC_model` defined above. \n",
    "\n",
    "**Background:**\n",
    "\n",
    "* Since the Adult dataset is imbalanced (about 24% positives, 76% negatives), accuracy alone is not reliable.\n",
    "* We will use the **F1 score** as the evaluation metric, since it balances precision (avoiding false positives) and recall (avoiding false negatives) in a single measure. This is a fairer metric for imbalanced classification, where both types of error matter.\n",
    "* We will apply **5-fold stratified cross-validation** to make sure each fold has the same proportion of the classes as the original dataset.\n",
    "* Repeated cross-validation is optional and not required here, because the Adult dataset is large and `HistGradientBoostingClassifier` is robust to small sampling differences. \n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Set up a `StratifiedKFold` cross-validation object with 5 splits, shuffling enabled, and `random_state=random_seed`.\n",
    "2. Use `cross_val_score` to estimate the mean F1 score and its standard deviation across the folds.\n",
    "3. Print out the mean and standard deviation of the F1 score, rounded to 4 decimal places.\n",
    "4. Answer the graded question.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1 score:  0.7123\n",
      "Std of F1 score: 0.0043\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "    #cross_val_score is used to evaluate a models performance via cross validation\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=random_seed) \n",
    "scores = cross_val_score(estimator=pipelined_model,X=X,y=y,cv=skf,scoring='f1',n_jobs=-1) #in this case n_jobs=-1 which means use all available CPU cores\n",
    "\n",
    "#Compute the mean and std and print for up to 4 decimals\n",
    "\n",
    "mean_f1 = scores.mean()\n",
    "std_f1 = scores.std()\n",
    "\n",
    "print(f\"Mean F1 score:  {mean_f1:.4f}\")\n",
    "print(f\"Std of F1 score: {std_f1:.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 Graded Answer\n",
    "\n",
    "Set `a1` to the mean F1 score of the baseline model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a1 = mean_f1                     # replace 0 with an expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1 = 0.7123\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a1 = {a1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Hyperparameter Optimization with Randomized Search for F1\n",
    "\n",
    "In this problem, you will tune your `pipelined_model` using `RandomizedSearchCV` to identify the best combination of tree structure and learning rate parameters that maximize the **F1 score**.\n",
    "\n",
    "**Background:**\n",
    "The F1 score is our main metric because it balances precision and recall on an imbalanced dataset. Optimizing hyperparameters for F1 ensures we manage both false positives and false negatives in a single measure.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Set up a randomized search over the following hyperparameter ranges, using appropriate random-number distributions:\n",
    "\n",
    "   * `learning_rate` (log-uniform between 1e-3 and 0.3)\n",
    "   * `max_leaf_nodes` (integer from 16 to 256)\n",
    "   * `max_depth` (integer from 2 to 10)\n",
    "   * `min_samples_leaf` (integer from 10 to 200)\n",
    "   * `l2_regularization` (uniform between 0.0 and 2.0)\n",
    "2. Use **5-fold stratified cross-validation**, with the same settings as in Problem 1.\n",
    "3. Set `n_iter` to at least 100 trials. More trials will generally yield better results, if your time and machine allow.\n",
    "4. After running the search, show a neatly formatted table of the top 5 results, using `display(...)` showing their mean F1 scores, standard deviation, and the chosen hyperparameter values.\n",
    "5. Answer the graded question.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>param_gb__l2_regularization</th>\n",
       "      <th>param_gb__learning_rate</th>\n",
       "      <th>param_gb__max_depth</th>\n",
       "      <th>param_gb__max_leaf_nodes</th>\n",
       "      <th>param_gb__min_samples_leaf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.7138</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.257001</td>\n",
       "      <td>0.102200</td>\n",
       "      <td>4</td>\n",
       "      <td>116</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.7138</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.772205</td>\n",
       "      <td>0.240428</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7137</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.764924</td>\n",
       "      <td>0.272635</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.7134</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>1.689068</td>\n",
       "      <td>0.070991</td>\n",
       "      <td>8</td>\n",
       "      <td>68</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.7132</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.186206</td>\n",
       "      <td>0.166921</td>\n",
       "      <td>6</td>\n",
       "      <td>175</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_test_score  std_test_score  param_gb__l2_regularization  \\\n",
       "97           0.7138          0.0049                     0.257001   \n",
       "98           0.7138          0.0059                     0.772205   \n",
       "7            0.7137          0.0046                     0.764924   \n",
       "16           0.7134          0.0044                     1.689068   \n",
       "51           0.7132          0.0048                     0.186206   \n",
       "\n",
       "    param_gb__learning_rate  param_gb__max_depth  param_gb__max_leaf_nodes  \\\n",
       "97                 0.102200                    4                       116   \n",
       "98                 0.240428                    3                        58   \n",
       "7                  0.272635                    2                       146   \n",
       "16                 0.070991                    8                        68   \n",
       "51                 0.166921                    6                       175   \n",
       "\n",
       "    param_gb__min_samples_leaf  \n",
       "97                          21  \n",
       "98                          53  \n",
       "7                           60  \n",
       "16                          33  \n",
       "51                          18  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here\n",
    "    #The reason we are using F1 score is due to being a single numeric metric that balances precision and recall which are 2 key measure  of the classifiers performance\n",
    "    # Precision is pretty much defined as Precision = True positives/True positives+False Positives (this tells you what fraction were actually positive)\n",
    "    #Recall is also called the sensitivity or the true positive rate  which is defined as: Recall = True positives/True positives+False Negatives this tells what fraction of the model was correclty identified.\n",
    "\n",
    "parameters = {\n",
    "  'gb__learning_rate':    loguniform(1e-3, 0.3),\n",
    "  'gb__max_leaf_nodes':   randint(16, 256),\n",
    "  'gb__max_depth':        randint(2, 10),\n",
    "  'gb__min_samples_leaf': randint(10, 200),\n",
    "  'gb__l2_regularization':uniform(0.0, 2.0)\n",
    "}\n",
    "randSearchCV = RandomizedSearchCV(estimator=pipelined_model,param_distributions=parameters,n_iter=100,scoring='f1',cv=skf,n_jobs=-1,random_state=random_seed,return_train_score=False)\n",
    "\n",
    "#Run the search\n",
    "randSearchCV.fit(X,y)\n",
    "results=pd.DataFrame(randSearchCV.cv_results_)\n",
    "\n",
    "\n",
    "#Grab the columns that we care about \n",
    "cols = ['mean_test_score','std_test_score']+[c for c in results.columns if c.startswith('param_')]\n",
    "top5 = results.sort_values('mean_test_score',ascending=False).head(5)\n",
    "\n",
    "# Round scores to 4 decimals\n",
    "top5['mean_test_score'] = top5['mean_test_score'].round(4)\n",
    "top5['std_test_score']  = top5['std_test_score'].round(4)\n",
    "\n",
    "display(top5[ ['mean_test_score','std_test_score'] + [c for c in top5.columns if c.startswith('param_')] ])\n",
    "\n",
    "\n",
    "    #loguniform is a sampling distribution that picks values uniformly in log-space rather than linear space. Which means that you would still likely sample 10^-3,10^-2 etc as you would any other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 Graded Answer\n",
    "\n",
    "Set `a2` to the mean F1 score of the best model found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a2 = 0.7138                    # replace 0 with your answer, may copy from the displayed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2 = 0.7138\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a2 = {a2:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Hyperparameter Optimization with Optuna for F1\n",
    "\n",
    "In this problem, you will explore **Optuna**, a powerful hyperparameter optimization framework, to identify the best combination of hyperparameters that maximize the F1 score of your `pipelined_model`.\n",
    "\n",
    "**Background:**\n",
    "Optuna uses a smarter sampling strategy than grid search or randomized search, allowing you to explore the hyperparameter space more efficiently. It also supports *pruning*, which can stop unpromising trials early to save time. This makes it a popular SOTA optimization tool.\n",
    "\n",
    "**Before you start** browse the [Optuna documentation](https://optuna.org) and view the [tutorial video](https://optuna.readthedocs.io/en/stable/tutorial/index.html). \n",
    "\n",
    "As before, we focus on the **F1 score** because it balances precision and recall, making it more robust on an imbalanced dataset.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Define an Optuna objective function to optimize F1 score, sampling the exact same hyperparameter ranges you did in Problem 2 and using the same CV settings.  \n",
    "3. Set up an Optuna study with a reasonable number of trials (e.g., 100–500 depending on runtime resources--on my machine Optuna runs about 10x faster than randomized search for the same number of trials, but YMMV).\n",
    "4. After running the optimization, `display` a clean table with the top 5 trials showing their F1 scores and corresponding hyperparameter settings.\n",
    "5. Answer the graded question. \n",
    "\n",
    "**Note:**  There are many resources on Optuna you can find on the web, but for this problem, you have my permission to let ChatGPT write the code for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:19:31,989] A new study created in memory with name: no-name-452628f8-e76d-4d9a-bbae-6582d14fc805\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n",
      "Best trial: 0. Best value: 0.706025:   0%|          | 1/200 [00:02<08:25,  2.54s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:19:34,533] Trial 0 finished with value: 0.7060254683812308 and parameters: {'learning_rate': 0.034335905175343476, 'max_leaf_nodes': 40, 'max_depth': 3, 'min_samples_leaf': 50, 'l2_regularization': 0.6053597411907907}. Best is trial 0 with value: 0.7060254683812308.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.709667:   1%|          | 2/200 [00:05<09:01,  2.73s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:19:37,400] Trial 1 finished with value: 0.7096667717354972 and parameters: {'learning_rate': 0.05752377011438329, 'max_leaf_nodes': 238, 'max_depth': 9, 'min_samples_leaf': 125, 'l2_regularization': 1.2890812137015297}. Best is trial 1 with value: 0.7096667717354972.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.712399:   2%|▏         | 3/200 [00:07<08:09,  2.48s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:19:39,588] Trial 2 finished with value: 0.7123989787878907 and parameters: {'learning_rate': 0.22120408743232475, 'max_leaf_nodes': 63, 'max_depth': 2, 'min_samples_leaf': 161, 'l2_regularization': 0.22026579079318953}. Best is trial 2 with value: 0.7123989787878907.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:   2%|▏         | 4/200 [00:10<08:35,  2.63s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:19:42,438] Trial 3 finished with value: 0.7126239886023866 and parameters: {'learning_rate': 0.0772588642518522, 'max_leaf_nodes': 134, 'max_depth': 4, 'min_samples_leaf': 136, 'l2_regularization': 1.4616880474482834}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:   2%|▎         | 5/200 [00:13<08:39,  2.67s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:19:45,172] Trial 4 finished with value: 0.7109055455175949 and parameters: {'learning_rate': 0.04658391045271985, 'max_leaf_nodes': 67, 'max_depth': 10, 'min_samples_leaf': 37, 'l2_regularization': 1.5028537678817975}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:   3%|▎         | 6/200 [00:17<10:35,  3.28s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:19:49,627] Trial 5 finished with value: 0.7045208023481015 and parameters: {'learning_rate': 0.011616056840017005, 'max_leaf_nodes': 198, 'max_depth': 8, 'min_samples_leaf': 53, 'l2_regularization': 0.8292858697922021}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:   4%|▎         | 7/200 [00:18<08:11,  2.55s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:19:50,671] Trial 6 finished with value: 0.7101809896416775 and parameters: {'learning_rate': 0.2125385232432619, 'max_leaf_nodes': 133, 'max_depth': 9, 'min_samples_leaf': 173, 'l2_regularization': 0.11641272135836145}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:   4%|▍         | 8/200 [00:19<06:42,  2.09s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:19:51,799] Trial 7 finished with value: 0.7115874587494946 and parameters: {'learning_rate': 0.22733552990724148, 'max_leaf_nodes': 174, 'max_depth': 6, 'min_samples_leaf': 157, 'l2_regularization': 1.9107680460481435}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:   4%|▍         | 9/200 [00:20<05:29,  1.73s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:19:52,713] Trial 8 finished with value: 0.7094409922090464 and parameters: {'learning_rate': 0.28688225655403043, 'max_leaf_nodes': 79, 'max_depth': 10, 'min_samples_leaf': 140, 'l2_regularization': 1.7814783896158843}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:   5%|▌         | 10/200 [00:25<08:05,  2.56s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:19:57,127] Trial 9 finished with value: 0.675573955826549 and parameters: {'learning_rate': 0.0018610842268440978, 'max_leaf_nodes': 42, 'max_depth': 10, 'min_samples_leaf': 167, 'l2_regularization': 0.03819017034397376}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:   6%|▌         | 11/200 [00:28<08:46,  2.78s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:00,427] Trial 10 finished with value: 0.6876374251047782 and parameters: {'learning_rate': 0.008943837152775311, 'max_leaf_nodes': 116, 'max_depth': 5, 'min_samples_leaf': 81, 'l2_regularization': 1.22120737229177}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:   6%|▌         | 12/200 [00:30<08:06,  2.59s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:02,565] Trial 11 finished with value: 0.7088776964023056 and parameters: {'learning_rate': 0.09935870357326937, 'max_leaf_nodes': 104, 'max_depth': 2, 'min_samples_leaf': 102, 'l2_regularization': 0.46907966945516466}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:   6%|▋         | 13/200 [00:33<07:58,  2.56s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:05,063] Trial 12 finished with value: 0.7117365509814494 and parameters: {'learning_rate': 0.10053591568342161, 'max_leaf_nodes': 172, 'max_depth': 4, 'min_samples_leaf': 200, 'l2_regularization': 0.9976931866703792}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:   7%|▋         | 14/200 [00:35<07:34,  2.44s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:07,240] Trial 13 finished with value: 0.6874689029283608 and parameters: {'learning_rate': 0.02314835231506037, 'max_leaf_nodes': 79, 'max_depth': 2, 'min_samples_leaf': 113, 'l2_regularization': 1.5042400915340277}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:   8%|▊         | 15/200 [00:37<07:32,  2.45s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:09,696] Trial 14 finished with value: 0.7124836370091134 and parameters: {'learning_rate': 0.1023326940800766, 'max_leaf_nodes': 22, 'max_depth': 4, 'min_samples_leaf': 199, 'l2_regularization': 0.43565641942211764}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:   8%|▊         | 16/200 [00:40<07:52,  2.57s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:12,542] Trial 15 finished with value: 0.6743340344243199 and parameters: {'learning_rate': 0.006622476499904288, 'max_leaf_nodes': 16, 'max_depth': 4, 'min_samples_leaf': 88, 'l2_regularization': 0.603180231088552}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:   8%|▊         | 17/200 [00:43<07:44,  2.54s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:15,007] Trial 16 finished with value: 0.7119641933335765 and parameters: {'learning_rate': 0.09460508997502784, 'max_leaf_nodes': 256, 'max_depth': 6, 'min_samples_leaf': 193, 'l2_regularization': 0.9276484082908534}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:   9%|▉         | 18/200 [00:47<09:03,  2.99s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:19,039] Trial 17 finished with value: 0.6696964572607922 and parameters: {'learning_rate': 0.0028309174886443126, 'max_leaf_nodes': 176, 'max_depth': 6, 'min_samples_leaf': 139, 'l2_regularization': 0.3605830336136934}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:  10%|▉         | 19/200 [00:50<08:59,  2.98s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:22,010] Trial 18 finished with value: 0.6966937290475343 and parameters: {'learning_rate': 0.01926618090982476, 'max_leaf_nodes': 215, 'max_depth': 4, 'min_samples_leaf': 188, 'l2_regularization': 1.2933091863091342}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:  10%|█         | 20/200 [00:52<08:25,  2.81s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:24,406] Trial 19 finished with value: 0.7114138918345562 and parameters: {'learning_rate': 0.07100891103134327, 'max_leaf_nodes': 144, 'max_depth': 5, 'min_samples_leaf': 21, 'l2_regularization': 1.6120170557461753}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:  10%|█         | 21/200 [00:55<08:16,  2.77s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:27,105] Trial 20 finished with value: 0.7017714174738299 and parameters: {'learning_rate': 0.029216232748850428, 'max_leaf_nodes': 147, 'max_depth': 3, 'min_samples_leaf': 142, 'l2_regularization': 0.7325746016492369}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:  11%|█         | 22/200 [00:57<07:48,  2.63s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:29,400] Trial 21 finished with value: 0.7126218317739695 and parameters: {'learning_rate': 0.14713230157598792, 'max_leaf_nodes': 21, 'max_depth': 3, 'min_samples_leaf': 174, 'l2_regularization': 0.23199049046934753}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.712624:  12%|█▏        | 23/200 [00:59<07:22,  2.50s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:31,606] Trial 22 finished with value: 0.712599447501795 and parameters: {'learning_rate': 0.12914829460225358, 'max_leaf_nodes': 17, 'max_depth': 3, 'min_samples_leaf': 178, 'l2_regularization': 0.3506842378866075}. Best is trial 3 with value: 0.7126239886023866.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 23. Best value: 0.713122:  12%|█▏        | 24/200 [01:01<07:08,  2.43s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:33,875] Trial 23 finished with value: 0.713121987537694 and parameters: {'learning_rate': 0.1333320511440783, 'max_leaf_nodes': 34, 'max_depth': 3, 'min_samples_leaf': 178, 'l2_regularization': 0.3027519679547648}. Best is trial 23 with value: 0.713121987537694.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: 0.713359:  12%|█▎        | 25/200 [01:03<06:46,  2.32s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:35,947] Trial 24 finished with value: 0.7133592006693145 and parameters: {'learning_rate': 0.15383014485801474, 'max_leaf_nodes': 50, 'max_depth': 3, 'min_samples_leaf': 153, 'l2_regularization': 1.1072062213948408}. Best is trial 24 with value: 0.7133592006693145.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: 0.713359:  13%|█▎        | 26/200 [01:06<07:17,  2.52s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:38,912] Trial 25 finished with value: 0.709415861718199 and parameters: {'learning_rate': 0.04116621840849373, 'max_leaf_nodes': 101, 'max_depth': 5, 'min_samples_leaf': 150, 'l2_regularization': 1.1636460766448784}. Best is trial 24 with value: 0.7133592006693145.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: 0.713359:  14%|█▎        | 27/200 [01:08<06:11,  2.14s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:40,188] Trial 26 finished with value: 0.7101402677529889 and parameters: {'learning_rate': 0.15675833038397352, 'max_leaf_nodes': 47, 'max_depth': 7, 'min_samples_leaf': 126, 'l2_regularization': 1.103838499517864}. Best is trial 24 with value: 0.7133592006693145.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: 0.713359:  14%|█▍        | 28/200 [01:10<06:22,  2.22s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:42,593] Trial 27 finished with value: 0.7108398094406552 and parameters: {'learning_rate': 0.06026384063914242, 'max_leaf_nodes': 88, 'max_depth': 3, 'min_samples_leaf': 124, 'l2_regularization': 1.378967112799997}. Best is trial 24 with value: 0.7133592006693145.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: 0.713359:  14%|█▍        | 29/200 [01:12<06:14,  2.19s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:44,717] Trial 28 finished with value: 0.7128979922624933 and parameters: {'learning_rate': 0.1726255693582465, 'max_leaf_nodes': 54, 'max_depth': 2, 'min_samples_leaf': 102, 'l2_regularization': 1.04050621392322}. Best is trial 24 with value: 0.7133592006693145.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 24. Best value: 0.713359:  15%|█▌        | 30/200 [01:14<06:11,  2.18s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:46,878] Trial 29 finished with value: 0.7117008771262867 and parameters: {'learning_rate': 0.1572904459022325, 'max_leaf_nodes': 55, 'max_depth': 2, 'min_samples_leaf': 69, 'l2_regularization': 0.6275010549491552}. Best is trial 24 with value: 0.7133592006693145.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 30. Best value: 0.713429:  16%|█▌        | 31/200 [01:16<05:21,  1.91s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:48,134] Trial 30 finished with value: 0.7134292979449335 and parameters: {'learning_rate': 0.2972030599805895, 'max_leaf_nodes': 33, 'max_depth': 3, 'min_samples_leaf': 105, 'l2_regularization': 0.8357643923838391}. Best is trial 30 with value: 0.7134292979449335.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 30. Best value: 0.713429:  16%|█▌        | 32/200 [01:17<05:07,  1.83s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:49,781] Trial 31 finished with value: 0.7120289492280888 and parameters: {'learning_rate': 0.29134107288458677, 'max_leaf_nodes': 37, 'max_depth': 3, 'min_samples_leaf': 100, 'l2_regularization': 0.8838203034182063}. Best is trial 30 with value: 0.7134292979449335.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 30. Best value: 0.713429:  16%|█▋        | 33/200 [01:19<05:20,  1.92s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:51,911] Trial 32 finished with value: 0.7123447006937356 and parameters: {'learning_rate': 0.18560551765060893, 'max_leaf_nodes': 37, 'max_depth': 2, 'min_samples_leaf': 115, 'l2_regularization': 1.0340820951740437}. Best is trial 30 with value: 0.7134292979449335.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  17%|█▋        | 34/200 [01:21<04:54,  1.77s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:53,351] Trial 33 finished with value: 0.7151779260860391 and parameters: {'learning_rate': 0.2899649573255102, 'max_leaf_nodes': 67, 'max_depth': 3, 'min_samples_leaf': 80, 'l2_regularization': 0.7667725265805693}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  18%|█▊        | 35/200 [01:22<04:24,  1.61s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:54,563] Trial 34 finished with value: 0.7146243118187001 and parameters: {'learning_rate': 0.27997473440373355, 'max_leaf_nodes': 66, 'max_depth': 3, 'min_samples_leaf': 65, 'l2_regularization': 0.7635922026225035}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  18%|█▊        | 36/200 [01:23<03:49,  1.40s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:55,481] Trial 35 finished with value: 0.7116493634054245 and parameters: {'learning_rate': 0.2903491966953175, 'max_leaf_nodes': 64, 'max_depth': 5, 'min_samples_leaf': 60, 'l2_regularization': 0.7568453373066368}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  18%|█▊        | 37/200 [01:24<03:33,  1.31s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:56,579] Trial 36 finished with value: 0.7130065588978767 and parameters: {'learning_rate': 0.22828326818994604, 'max_leaf_nodes': 71, 'max_depth': 4, 'min_samples_leaf': 38, 'l2_regularization': 0.6248134138126342}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  19%|█▉        | 38/200 [01:26<03:40,  1.36s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:58,069] Trial 37 finished with value: 0.7127789006301823 and parameters: {'learning_rate': 0.23573256878946877, 'max_leaf_nodes': 93, 'max_depth': 3, 'min_samples_leaf': 81, 'l2_regularization': 0.7282116099302639}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  20%|█▉        | 39/200 [01:27<04:03,  1.51s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:20:59,923] Trial 38 finished with value: 0.7138792535645127 and parameters: {'learning_rate': 0.2999486229192199, 'max_leaf_nodes': 115, 'max_depth': 2, 'min_samples_leaf': 89, 'l2_regularization': 0.8799689236652013}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  20%|██        | 40/200 [01:29<04:16,  1.60s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:01,739] Trial 39 finished with value: 0.7133170121271363 and parameters: {'learning_rate': 0.29377113309805986, 'max_leaf_nodes': 122, 'max_depth': 2, 'min_samples_leaf': 71, 'l2_regularization': 0.8093060231677975}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  20%|██        | 41/200 [01:31<04:44,  1.79s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:03,958] Trial 40 finished with value: 0.6059676872517383 and parameters: {'learning_rate': 0.0011154282110526182, 'max_leaf_nodes': 111, 'max_depth': 2, 'min_samples_leaf': 88, 'l2_regularization': 0.5233077436918555}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  21%|██        | 42/200 [01:33<04:15,  1.62s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:05,178] Trial 41 finished with value: 0.7125689352108583 and parameters: {'learning_rate': 0.20317926048632226, 'max_leaf_nodes': 74, 'max_depth': 4, 'min_samples_leaf': 55, 'l2_regularization': 0.9241651044010046}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  22%|██▏       | 43/200 [01:34<04:13,  1.61s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:06,788] Trial 42 finished with value: 0.7124079152579201 and parameters: {'learning_rate': 0.22572846503789648, 'max_leaf_nodes': 57, 'max_depth': 3, 'min_samples_leaf': 95, 'l2_regularization': 0.8412552153343269}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  22%|██▏       | 44/200 [01:36<04:25,  1.70s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:08,686] Trial 43 finished with value: 0.7133843753549819 and parameters: {'learning_rate': 0.18915900334666416, 'max_leaf_nodes': 90, 'max_depth': 3, 'min_samples_leaf': 72, 'l2_regularization': 0.6761928817118907}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  22%|██▎       | 45/200 [01:38<04:42,  1.82s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:10,794] Trial 44 finished with value: 0.7123165294076956 and parameters: {'learning_rate': 0.11949505338250468, 'max_leaf_nodes': 89, 'max_depth': 2, 'min_samples_leaf': 41, 'l2_regularization': 0.6964756449201829}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  23%|██▎       | 46/200 [01:41<05:13,  2.03s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:13,324] Trial 45 finished with value: 0.7134477767746685 and parameters: {'learning_rate': 0.0742171935959008, 'max_leaf_nodes': 120, 'max_depth': 4, 'min_samples_leaf': 74, 'l2_regularization': 0.5222196047523344}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  24%|██▎       | 47/200 [01:43<05:39,  2.22s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:15,977] Trial 46 finished with value: 0.711831294681138 and parameters: {'learning_rate': 0.049269074604817074, 'max_leaf_nodes': 131, 'max_depth': 4, 'min_samples_leaf': 65, 'l2_regularization': 0.5376197179459402}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  24%|██▍       | 48/200 [01:46<05:29,  2.17s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:18,029] Trial 47 finished with value: 0.7092852200571175 and parameters: {'learning_rate': 0.08063404049561258, 'max_leaf_nodes': 162, 'max_depth': 2, 'min_samples_leaf': 80, 'l2_regularization': 0.9533896340873822}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  24%|██▍       | 49/200 [01:50<07:28,  2.97s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:22,877] Trial 48 finished with value: 0.7065181471917544 and parameters: {'learning_rate': 0.012288744724321623, 'max_leaf_nodes': 121, 'max_depth': 9, 'min_samples_leaf': 45, 'l2_regularization': 0.834256308998764}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  25%|██▌       | 50/200 [01:51<05:50,  2.34s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:23,739] Trial 49 finished with value: 0.7100890803545358 and parameters: {'learning_rate': 0.24070150770073437, 'max_leaf_nodes': 100, 'max_depth': 8, 'min_samples_leaf': 89, 'l2_regularization': 0.4615375874361326}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  26%|██▌       | 51/200 [01:54<05:59,  2.42s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:26,332] Trial 50 finished with value: 0.7125817897408904 and parameters: {'learning_rate': 0.07562243949286877, 'max_leaf_nodes': 30, 'max_depth': 4, 'min_samples_leaf': 109, 'l2_regularization': 0.5167836493036733}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  26%|██▌       | 52/200 [01:56<05:27,  2.21s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:28,067] Trial 51 finished with value: 0.7136918040101804 and parameters: {'learning_rate': 0.19403413694499738, 'max_leaf_nodes': 111, 'max_depth': 3, 'min_samples_leaf': 74, 'l2_regularization': 0.670146809211516}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  26%|██▋       | 53/200 [01:58<05:26,  2.22s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:30,319] Trial 52 finished with value: 0.7131703707273663 and parameters: {'learning_rate': 0.11976495143385446, 'max_leaf_nodes': 152, 'max_depth': 3, 'min_samples_leaf': 77, 'l2_regularization': 0.7982524814114151}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  27%|██▋       | 54/200 [01:59<04:37,  1.90s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:31,460] Trial 53 finished with value: 0.713985297921849 and parameters: {'learning_rate': 0.2502304691006878, 'max_leaf_nodes': 111, 'max_depth': 4, 'min_samples_leaf': 59, 'l2_regularization': 0.5727117605776259}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  28%|██▊       | 55/200 [02:00<04:02,  1.67s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:32,601] Trial 54 finished with value: 0.711088605314468 and parameters: {'learning_rate': 0.1960264068363468, 'max_leaf_nodes': 130, 'max_depth': 5, 'min_samples_leaf': 28, 'l2_regularization': 0.5974099476474106}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  28%|██▊       | 56/200 [02:01<03:36,  1.50s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:33,702] Trial 55 finished with value: 0.7129050284105769 and parameters: {'learning_rate': 0.24444302304590773, 'max_leaf_nodes': 111, 'max_depth': 4, 'min_samples_leaf': 50, 'l2_regularization': 0.4316543964014039}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  28%|██▊       | 57/200 [02:04<04:35,  1.92s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:36,617] Trial 56 finished with value: 0.6657819955359576 and parameters: {'learning_rate': 0.004124640081247645, 'max_leaf_nodes': 80, 'max_depth': 4, 'min_samples_leaf': 61, 'l2_regularization': 0.1286199923428104}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  29%|██▉       | 58/200 [02:06<04:41,  1.98s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:38,730] Trial 57 finished with value: 0.7120267360117367 and parameters: {'learning_rate': 0.09714711148674819, 'max_leaf_nodes': 142, 'max_depth': 5, 'min_samples_leaf': 56, 'l2_regularization': 0.5783416832672493}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  30%|██▉       | 59/200 [02:08<04:47,  2.04s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:40,907] Trial 58 finished with value: 0.6940103803369484 and parameters: {'learning_rate': 0.030888351082649795, 'max_leaf_nodes': 123, 'max_depth': 2, 'min_samples_leaf': 90, 'l2_regularization': 0.6558237614852301}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  30%|███       | 60/200 [02:10<04:32,  1.95s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:42,633] Trial 59 finished with value: 0.7120859284685104 and parameters: {'learning_rate': 0.11533502942406795, 'max_leaf_nodes': 188, 'max_depth': 6, 'min_samples_leaf': 74, 'l2_regularization': 0.3989135502970692}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  30%|███       | 61/200 [02:12<04:14,  1.83s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:44,185] Trial 60 finished with value: 0.7134456790774393 and parameters: {'learning_rate': 0.17056811127936208, 'max_leaf_nodes': 107, 'max_depth': 4, 'min_samples_leaf': 33, 'l2_regularization': 0.7615825862167707}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  31%|███       | 62/200 [02:14<04:14,  1.85s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:46,077] Trial 61 finished with value: 0.7142464494957755 and parameters: {'learning_rate': 0.17193372223094994, 'max_leaf_nodes': 108, 'max_depth': 4, 'min_samples_leaf': 65, 'l2_regularization': 0.7163674881247125}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  32%|███▏      | 63/200 [02:15<04:05,  1.79s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:47,733] Trial 62 finished with value: 0.7126219467832458 and parameters: {'learning_rate': 0.24453924148232342, 'max_leaf_nodes': 96, 'max_depth': 3, 'min_samples_leaf': 65, 'l2_regularization': 0.7014088532137615}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  32%|███▏      | 64/200 [02:17<03:50,  1.70s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:49,210] Trial 63 finished with value: 0.7121845144797303 and parameters: {'learning_rate': 0.1913127672139301, 'max_leaf_nodes': 81, 'max_depth': 4, 'min_samples_leaf': 83, 'l2_regularization': 0.2926974563811896}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  32%|███▎      | 65/200 [02:18<03:51,  1.72s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:50,973] Trial 64 finished with value: 0.7132114228206204 and parameters: {'learning_rate': 0.1372897450857795, 'max_leaf_nodes': 117, 'max_depth': 5, 'min_samples_leaf': 49, 'l2_regularization': 0.9033368427049691}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  33%|███▎      | 66/200 [02:21<04:27,  2.00s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:53,626] Trial 65 finished with value: 0.7111815085122872 and parameters: {'learning_rate': 0.06077510632588933, 'max_leaf_nodes': 129, 'max_depth': 3, 'min_samples_leaf': 66, 'l2_regularization': 0.9744759866627685}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  34%|███▎      | 67/200 [02:24<04:47,  2.16s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:56,167] Trial 66 finished with value: 0.7126652080917449 and parameters: {'learning_rate': 0.08720750423267096, 'max_leaf_nodes': 106, 'max_depth': 3, 'min_samples_leaf': 59, 'l2_regularization': 0.552229497485296}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  34%|███▍      | 68/200 [02:25<03:58,  1.81s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:57,148] Trial 67 finished with value: 0.7114212402451061 and parameters: {'learning_rate': 0.258874352872236, 'max_leaf_nodes': 154, 'max_depth': 7, 'min_samples_leaf': 93, 'l2_regularization': 1.9328377651143498}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  34%|███▍      | 69/200 [02:27<04:14,  1.94s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:21:59,396] Trial 68 finished with value: 0.7119820917510612 and parameters: {'learning_rate': 0.14313029069495417, 'max_leaf_nodes': 140, 'max_depth': 2, 'min_samples_leaf': 84, 'l2_regularization': 0.6609737707235874}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  35%|███▌      | 70/200 [02:28<03:49,  1.77s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:00,762] Trial 69 finished with value: 0.7128464903095721 and parameters: {'learning_rate': 0.2026235231031067, 'max_leaf_nodes': 113, 'max_depth': 5, 'min_samples_leaf': 76, 'l2_regularization': 0.782740785464004}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  36%|███▌      | 71/200 [02:30<03:45,  1.75s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:02,472] Trial 70 finished with value: 0.712723001620276 and parameters: {'learning_rate': 0.16665239206620444, 'max_leaf_nodes': 67, 'max_depth': 4, 'min_samples_leaf': 97, 'l2_regularization': 0.4954647190738692}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  36%|███▌      | 72/200 [02:32<03:40,  1.73s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:04,144] Trial 71 finished with value: 0.7130342982106381 and parameters: {'learning_rate': 0.17002136834976808, 'max_leaf_nodes': 100, 'max_depth': 4, 'min_samples_leaf': 30, 'l2_regularization': 0.7427280787998828}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  36%|███▋      | 73/200 [02:33<03:16,  1.55s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:05,273] Trial 72 finished with value: 0.7125431310994332 and parameters: {'learning_rate': 0.26267075376513477, 'max_leaf_nodes': 105, 'max_depth': 4, 'min_samples_leaf': 14, 'l2_regularization': 0.8837318578842546}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  37%|███▋      | 74/200 [02:35<03:51,  1.84s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:07,796] Trial 73 finished with value: 0.7140170423841614 and parameters: {'learning_rate': 0.10368579877903406, 'max_leaf_nodes': 86, 'max_depth': 3, 'min_samples_leaf': 33, 'l2_regularization': 1.0431764303876918}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  38%|███▊      | 75/200 [02:38<04:14,  2.03s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:10,285] Trial 74 finished with value: 0.7139406032760055 and parameters: {'learning_rate': 0.10440489144936843, 'max_leaf_nodes': 87, 'max_depth': 3, 'min_samples_leaf': 46, 'l2_regularization': 1.2259583620468757}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  38%|███▊      | 76/200 [02:40<04:28,  2.17s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:12,762] Trial 75 finished with value: 0.7138089677042923 and parameters: {'learning_rate': 0.1044393601370949, 'max_leaf_nodes': 84, 'max_depth': 3, 'min_samples_leaf': 43, 'l2_regularization': 1.2307203294108742}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  38%|███▊      | 77/200 [02:43<04:30,  2.20s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:15,043] Trial 76 finished with value: 0.7111712321140091 and parameters: {'learning_rate': 0.11467692825467009, 'max_leaf_nodes': 44, 'max_depth': 2, 'min_samples_leaf': 43, 'l2_regularization': 1.234606256726663}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  39%|███▉      | 78/200 [02:45<04:41,  2.30s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:17,587] Trial 77 finished with value: 0.7121282351823187 and parameters: {'learning_rate': 0.09852113976150052, 'max_leaf_nodes': 84, 'max_depth': 3, 'min_samples_leaf': 20, 'l2_regularization': 1.3077434743173058}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  40%|███▉      | 79/200 [02:48<04:51,  2.41s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:20,231] Trial 78 finished with value: 0.7075041688218718 and parameters: {'learning_rate': 0.038422949307342594, 'max_leaf_nodes': 59, 'max_depth': 3, 'min_samples_leaf': 50, 'l2_regularization': 1.1318925773403226}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  40%|████      | 80/200 [02:50<04:48,  2.40s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:22,631] Trial 79 finished with value: 0.7056542437806363 and parameters: {'learning_rate': 0.05219692278816693, 'max_leaf_nodes': 74, 'max_depth': 2, 'min_samples_leaf': 40, 'l2_regularization': 1.4905975613618991}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  40%|████      | 81/200 [02:52<04:37,  2.33s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:24,782] Trial 80 finished with value: 0.7131536773526508 and parameters: {'learning_rate': 0.1401548530279566, 'max_leaf_nodes': 70, 'max_depth': 3, 'min_samples_leaf': 35, 'l2_regularization': 1.055707420310768}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  41%|████      | 82/200 [02:54<04:24,  2.24s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:26,821] Trial 81 finished with value: 0.7138208593930893 and parameters: {'learning_rate': 0.2247326101782267, 'max_leaf_nodes': 94, 'max_depth': 3, 'min_samples_leaf': 47, 'l2_regularization': 1.4173537253021529}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  42%|████▏     | 83/200 [02:56<04:10,  2.14s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:28,715] Trial 82 finished with value: 0.7143970585799877 and parameters: {'learning_rate': 0.21407563803448748, 'max_leaf_nodes': 95, 'max_depth': 3, 'min_samples_leaf': 53, 'l2_regularization': 1.5804865930073757}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  42%|████▏     | 84/200 [02:58<03:52,  2.00s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:30,398] Trial 83 finished with value: 0.7136445262197626 and parameters: {'learning_rate': 0.2998904770645721, 'max_leaf_nodes': 94, 'max_depth': 2, 'min_samples_leaf': 53, 'l2_regularization': 1.6966081835272204}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  42%|████▎     | 85/200 [03:00<03:46,  1.97s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:32,282] Trial 84 finished with value: 0.7141022045692694 and parameters: {'learning_rate': 0.2182334002757995, 'max_leaf_nodes': 75, 'max_depth': 3, 'min_samples_leaf': 48, 'l2_regularization': 1.559786380548378}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  43%|████▎     | 86/200 [03:02<03:43,  1.96s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:34,223] Trial 85 finished with value: 0.7146240880386918 and parameters: {'learning_rate': 0.2682142852338569, 'max_leaf_nodes': 61, 'max_depth': 2, 'min_samples_leaf': 61, 'l2_regularization': 1.85474262294191}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  44%|████▎     | 87/200 [03:03<03:31,  1.87s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:35,896] Trial 86 finished with value: 0.7116492014184501 and parameters: {'learning_rate': 0.26099823320570076, 'max_leaf_nodes': 61, 'max_depth': 3, 'min_samples_leaf': 60, 'l2_regularization': 1.6134494989071921}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  44%|████▍     | 88/200 [03:05<03:22,  1.81s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:37,561] Trial 87 finished with value: 0.7122999289782197 and parameters: {'learning_rate': 0.21556173745681068, 'max_leaf_nodes': 51, 'max_depth': 3, 'min_samples_leaf': 25, 'l2_regularization': 1.842619027733793}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  44%|████▍     | 89/200 [03:07<03:40,  1.99s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:39,959] Trial 88 finished with value: 0.7117653402424864 and parameters: {'learning_rate': 0.14733148977740987, 'max_leaf_nodes': 65, 'max_depth': 2, 'min_samples_leaf': 68, 'l2_regularization': 1.7303322944002957}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  45%|████▌     | 90/200 [03:09<03:31,  1.92s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:41,735] Trial 89 finished with value: 0.7141423936037298 and parameters: {'learning_rate': 0.16857988272016727, 'max_leaf_nodes': 75, 'max_depth': 3, 'min_samples_leaf': 56, 'l2_regularization': 1.5622849332347208}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  46%|████▌     | 91/200 [03:12<03:55,  2.16s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:44,432] Trial 90 finished with value: 0.712541828693195 and parameters: {'learning_rate': 0.17771852393096843, 'max_leaf_nodes': 72, 'max_depth': 2, 'min_samples_leaf': 54, 'l2_regularization': 1.5855344845010988}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  46%|████▌     | 92/200 [03:15<04:16,  2.38s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:47,330] Trial 91 finished with value: 0.7139243221950713 and parameters: {'learning_rate': 0.26697516540955424, 'max_leaf_nodes': 76, 'max_depth': 3, 'min_samples_leaf': 63, 'l2_regularization': 1.7951849179759416}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  46%|████▋     | 93/200 [03:17<04:08,  2.32s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:49,517] Trial 92 finished with value: 0.7134235002103643 and parameters: {'learning_rate': 0.21978476276888803, 'max_leaf_nodes': 80, 'max_depth': 3, 'min_samples_leaf': 56, 'l2_regularization': 1.5458250734465557}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  47%|████▋     | 94/200 [03:20<04:14,  2.40s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:52,106] Trial 93 finished with value: 0.7141573642255805 and parameters: {'learning_rate': 0.15669482454553302, 'max_leaf_nodes': 85, 'max_depth': 3, 'min_samples_leaf': 37, 'l2_regularization': 1.3512203599452373}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  48%|████▊     | 95/200 [03:22<04:11,  2.39s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:54,478] Trial 94 finished with value: 0.7125996273904234 and parameters: {'learning_rate': 0.15956960917396698, 'max_leaf_nodes': 66, 'max_depth': 4, 'min_samples_leaf': 52, 'l2_regularization': 1.659709733283567}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  48%|████▊     | 96/200 [03:24<03:53,  2.25s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:56,380] Trial 95 finished with value: 0.7137738967003292 and parameters: {'learning_rate': 0.1996822067739039, 'max_leaf_nodes': 49, 'max_depth': 3, 'min_samples_leaf': 37, 'l2_regularization': 1.3194774268494327}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  48%|████▊     | 97/200 [03:26<03:58,  2.32s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:22:58,863] Trial 96 finished with value: 0.6860902089463223 and parameters: {'learning_rate': 0.021842031446007097, 'max_leaf_nodes': 76, 'max_depth': 2, 'min_samples_leaf': 31, 'l2_regularization': 1.4368562555219198}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  49%|████▉     | 98/200 [03:29<03:58,  2.33s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:01,237] Trial 97 finished with value: 0.7135286480777353 and parameters: {'learning_rate': 0.12766582753803069, 'max_leaf_nodes': 223, 'max_depth': 4, 'min_samples_leaf': 70, 'l2_regularization': 1.3594120030588484}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  50%|████▉     | 99/200 [03:30<03:30,  2.09s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:02,743] Trial 98 finished with value: 0.714038468971909 and parameters: {'learning_rate': 0.2652848229353947, 'max_leaf_nodes': 55, 'max_depth': 3, 'min_samples_leaf': 58, 'l2_regularization': 1.8757693116712897}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  50%|█████     | 100/200 [03:32<03:13,  1.94s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:04,330] Trial 99 finished with value: 0.712308514284505 and parameters: {'learning_rate': 0.2187608558178055, 'max_leaf_nodes': 55, 'max_depth': 3, 'min_samples_leaf': 23, 'l2_regularization': 1.9944479400972412}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  50%|█████     | 101/200 [03:34<03:12,  1.95s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:06,303] Trial 100 finished with value: 0.7140721741580071 and parameters: {'learning_rate': 0.15376595197470166, 'max_leaf_nodes': 61, 'max_depth': 3, 'min_samples_leaf': 58, 'l2_regularization': 1.877673361018203}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  51%|█████     | 102/200 [03:36<03:10,  1.94s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:08,236] Trial 101 finished with value: 0.7140022381591572 and parameters: {'learning_rate': 0.17901149286229198, 'max_leaf_nodes': 61, 'max_depth': 3, 'min_samples_leaf': 58, 'l2_regularization': 1.8806989318958809}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  52%|█████▏    | 103/200 [03:37<02:55,  1.81s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:09,721] Trial 102 finished with value: 0.7134716165439574 and parameters: {'learning_rate': 0.2627096338365791, 'max_leaf_nodes': 69, 'max_depth': 3, 'min_samples_leaf': 62, 'l2_regularization': 1.7271392039776112}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  52%|█████▏    | 104/200 [03:39<03:05,  1.93s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:11,935] Trial 103 finished with value: 0.7130792869944675 and parameters: {'learning_rate': 0.1522912322176705, 'max_leaf_nodes': 45, 'max_depth': 2, 'min_samples_leaf': 39, 'l2_regularization': 1.8179895970451219}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  52%|█████▎    | 105/200 [03:42<03:15,  2.06s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:14,288] Trial 104 finished with value: 0.7135503765143756 and parameters: {'learning_rate': 0.1299474865885192, 'max_leaf_nodes': 84, 'max_depth': 3, 'min_samples_leaf': 46, 'l2_regularization': 1.9352128659102543}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  53%|█████▎    | 106/200 [03:44<03:29,  2.23s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:16,917] Trial 105 finished with value: 0.6885779667673948 and parameters: {'learning_rate': 0.015537241329512655, 'max_leaf_nodes': 41, 'max_depth': 3, 'min_samples_leaf': 66, 'l2_regularization': 1.5131369780917403}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  54%|█████▎    | 107/200 [03:47<03:30,  2.27s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:19,274] Trial 106 finished with value: 0.660872596075957 and parameters: {'learning_rate': 0.007090372199827149, 'max_leaf_nodes': 54, 'max_depth': 2, 'min_samples_leaf': 49, 'l2_regularization': 1.7548996632915002}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  54%|█████▍    | 108/200 [03:49<03:19,  2.17s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:21,227] Trial 107 finished with value: 0.713856585098994 and parameters: {'learning_rate': 0.1993501298600442, 'max_leaf_nodes': 90, 'max_depth': 3, 'min_samples_leaf': 35, 'l2_regularization': 1.99494813476025}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  55%|█████▍    | 109/200 [03:51<03:06,  2.05s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:23,000] Trial 108 finished with value: 0.7130940751457635 and parameters: {'learning_rate': 0.23035775427503732, 'max_leaf_nodes': 29, 'max_depth': 3, 'min_samples_leaf': 68, 'l2_regularization': 1.646577169102951}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  55%|█████▌    | 110/200 [03:53<03:08,  2.09s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:25,182] Trial 109 finished with value: 0.7135089679637063 and parameters: {'learning_rate': 0.17502171453446685, 'max_leaf_nodes': 62, 'max_depth': 2, 'min_samples_leaf': 54, 'l2_regularization': 1.8855515879856029}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  56%|█████▌    | 111/200 [03:54<02:41,  1.81s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:26,346] Trial 110 finished with value: 0.7116877888441039 and parameters: {'learning_rate': 0.27962375381137733, 'max_leaf_nodes': 78, 'max_depth': 4, 'min_samples_leaf': 78, 'l2_regularization': 1.6658361764599268}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  56%|█████▌    | 112/200 [03:56<02:45,  1.88s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:28,376] Trial 111 finished with value: 0.7140038715607405 and parameters: {'learning_rate': 0.16295938770163848, 'max_leaf_nodes': 60, 'max_depth': 3, 'min_samples_leaf': 63, 'l2_regularization': 1.8416528753963408}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  56%|█████▋    | 113/200 [03:58<02:50,  1.96s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:30,542] Trial 112 finished with value: 0.7142625314903215 and parameters: {'learning_rate': 0.15003414673944088, 'max_leaf_nodes': 70, 'max_depth': 3, 'min_samples_leaf': 63, 'l2_regularization': 1.5753231519198225}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  57%|█████▋    | 114/200 [03:59<02:33,  1.79s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:31,908] Trial 113 finished with value: 0.7137301842991532 and parameters: {'learning_rate': 0.24259165339667185, 'max_leaf_nodes': 69, 'max_depth': 3, 'min_samples_leaf': 57, 'l2_regularization': 1.5891643421154447}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  57%|█████▊    | 115/200 [04:02<02:46,  1.96s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:34,270] Trial 114 finished with value: 0.7129351877245789 and parameters: {'learning_rate': 0.08647933371305977, 'max_leaf_nodes': 86, 'max_depth': 3, 'min_samples_leaf': 42, 'l2_regularization': 1.527845637328863}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  58%|█████▊    | 116/200 [04:04<02:51,  2.04s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:36,511] Trial 115 finished with value: 0.7139689403455766 and parameters: {'learning_rate': 0.11439103532366982, 'max_leaf_nodes': 98, 'max_depth': 3, 'min_samples_leaf': 71, 'l2_regularization': 1.390139461765163}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 33. Best value: 0.715178:  58%|█████▊    | 117/200 [04:06<02:48,  2.03s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:38,519] Trial 116 finished with value: 0.7135549957215594 and parameters: {'learning_rate': 0.20591655279132584, 'max_leaf_nodes': 72, 'max_depth': 2, 'min_samples_leaf': 84, 'l2_regularization': 1.4696318384540814}. Best is trial 33 with value: 0.7151779260860391.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  59%|█████▉    | 118/200 [04:08<02:49,  2.07s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:40,677] Trial 117 finished with value: 0.715467416975452 and parameters: {'learning_rate': 0.14805159568678647, 'max_leaf_nodes': 51, 'max_depth': 3, 'min_samples_leaf': 52, 'l2_regularization': 1.7546566345920889}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  60%|█████▉    | 119/200 [04:10<02:34,  1.91s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:42,221] Trial 118 finished with value: 0.7145461355764773 and parameters: {'learning_rate': 0.185618723785627, 'max_leaf_nodes': 51, 'max_depth': 4, 'min_samples_leaf': 53, 'l2_regularization': 1.7659949587993402}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  60%|██████    | 120/200 [04:12<02:33,  1.92s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:44,166] Trial 119 finished with value: 0.7124674221873886 and parameters: {'learning_rate': 0.1450423071000015, 'max_leaf_nodes': 46, 'max_depth': 4, 'min_samples_leaf': 52, 'l2_regularization': 1.7739312510317848}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  60%|██████    | 121/200 [04:13<02:21,  1.79s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:45,656] Trial 120 finished with value: 0.7123029664464366 and parameters: {'learning_rate': 0.1293909043785927, 'max_leaf_nodes': 36, 'max_depth': 5, 'min_samples_leaf': 47, 'l2_regularization': 1.567012132383234}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  61%|██████    | 122/200 [04:15<02:20,  1.80s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:47,465] Trial 121 finished with value: 0.7132351324966352 and parameters: {'learning_rate': 0.18814390078009202, 'max_leaf_nodes': 51, 'max_depth': 3, 'min_samples_leaf': 61, 'l2_regularization': 1.7009381863045254}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  62%|██████▏   | 123/200 [04:16<01:55,  1.50s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:48,284] Trial 122 finished with value: 0.71133283767398 and parameters: {'learning_rate': 0.29987469730909244, 'max_leaf_nodes': 55, 'max_depth': 7, 'min_samples_leaf': 56, 'l2_regularization': 1.8764514192270192}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  62%|██████▏   | 124/200 [04:17<01:54,  1.50s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:49,783] Trial 123 finished with value: 0.7132492101721337 and parameters: {'learning_rate': 0.2391358625836642, 'max_leaf_nodes': 64, 'max_depth': 3, 'min_samples_leaf': 64, 'l2_regularization': 1.938511226293946}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  62%|██████▎   | 125/200 [04:19<01:58,  1.58s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:51,531] Trial 124 finished with value: 0.7125394907034405 and parameters: {'learning_rate': 0.16150244488638268, 'max_leaf_nodes': 76, 'max_depth': 4, 'min_samples_leaf': 51, 'l2_regularization': 1.806383919848882}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  63%|██████▎   | 126/200 [04:21<01:58,  1.60s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:53,186] Trial 125 finished with value: 0.7136546598898442 and parameters: {'learning_rate': 0.20868533218768337, 'max_leaf_nodes': 58, 'max_depth': 3, 'min_samples_leaf': 73, 'l2_regularization': 1.739511148838087}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  64%|██████▎   | 127/200 [04:23<02:15,  1.86s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:55,647] Trial 126 finished with value: 0.6539565004334211 and parameters: {'learning_rate': 0.003457242306203381, 'max_leaf_nodes': 66, 'max_depth': 3, 'min_samples_leaf': 59, 'l2_regularization': 1.6881458286610493}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  64%|██████▍   | 128/200 [04:25<02:07,  1.76s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:57,192] Trial 127 finished with value: 0.7125431125969333 and parameters: {'learning_rate': 0.18315403501103503, 'max_leaf_nodes': 26, 'max_depth': 4, 'min_samples_leaf': 43, 'l2_regularization': 1.607093144063105}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  64%|██████▍   | 129/200 [04:26<02:04,  1.75s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:58,902] Trial 128 finished with value: 0.7138145363775016 and parameters: {'learning_rate': 0.26948867603391813, 'max_leaf_nodes': 52, 'max_depth': 2, 'min_samples_leaf': 66, 'l2_regularization': 1.8486287566963961}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  65%|██████▌   | 130/200 [04:27<01:44,  1.50s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:23:59,812] Trial 129 finished with value: 0.7109881255932654 and parameters: {'learning_rate': 0.22135010621978005, 'max_leaf_nodes': 39, 'max_depth': 10, 'min_samples_leaf': 49, 'l2_regularization': 1.6306434783372534}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  66%|██████▌   | 131/200 [04:29<01:54,  1.66s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:01,848] Trial 130 finished with value: 0.7136563510513495 and parameters: {'learning_rate': 0.14398391815607536, 'max_leaf_nodes': 48, 'max_depth': 3, 'min_samples_leaf': 55, 'l2_regularization': 1.913884712254919}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  66%|██████▌   | 132/200 [04:32<02:06,  1.86s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:04,186] Trial 131 finished with value: 0.713290876901391 and parameters: {'learning_rate': 0.11332127718557337, 'max_leaf_nodes': 91, 'max_depth': 3, 'min_samples_leaf': 28, 'l2_regularization': 1.4654635036969594}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  66%|██████▋   | 133/200 [04:34<02:04,  1.85s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:06,017] Trial 132 finished with value: 0.7138740088214326 and parameters: {'learning_rate': 0.1589094028150471, 'max_leaf_nodes': 82, 'max_depth': 3, 'min_samples_leaf': 38, 'l2_regularization': 1.7813191086057636}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  67%|██████▋   | 134/200 [04:36<02:05,  1.91s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:08,049] Trial 133 finished with value: 0.713469114258553 and parameters: {'learning_rate': 0.1763528827802963, 'max_leaf_nodes': 72, 'max_depth': 3, 'min_samples_leaf': 17, 'l2_regularization': 1.1745178342674696}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  68%|██████▊   | 135/200 [04:37<01:57,  1.81s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:09,644] Trial 134 finished with value: 0.714238571582361 and parameters: {'learning_rate': 0.24204353759712047, 'max_leaf_nodes': 78, 'max_depth': 3, 'min_samples_leaf': 46, 'l2_regularization': 1.5576556983385674}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  68%|██████▊   | 136/200 [04:38<01:44,  1.63s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:10,858] Trial 135 finished with value: 0.7128900071436227 and parameters: {'learning_rate': 0.24061905030631517, 'max_leaf_nodes': 79, 'max_depth': 4, 'min_samples_leaf': 47, 'l2_regularization': 1.5547773267226608}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  68%|██████▊   | 137/200 [04:40<01:40,  1.59s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:12,338] Trial 136 finished with value: 0.7134875846286722 and parameters: {'learning_rate': 0.266253992958825, 'max_leaf_nodes': 59, 'max_depth': 3, 'min_samples_leaf': 60, 'l2_regularization': 1.9657974810314278}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  69%|██████▉   | 138/200 [04:42<01:46,  1.72s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:14,381] Trial 137 finished with value: 0.7129332891242479 and parameters: {'learning_rate': 0.20200902614729885, 'max_leaf_nodes': 66, 'max_depth': 2, 'min_samples_leaf': 54, 'l2_regularization': 1.7089984369203597}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  70%|██████▉   | 139/200 [04:44<01:45,  1.72s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:16,108] Trial 138 finished with value: 0.7139189958100213 and parameters: {'learning_rate': 0.23611700843178332, 'max_leaf_nodes': 74, 'max_depth': 3, 'min_samples_leaf': 44, 'l2_regularization': 1.5146784566126679}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  70%|███████   | 140/200 [04:46<02:03,  2.06s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:18,952] Trial 139 finished with value: 0.6504660283147213 and parameters: {'learning_rate': 0.0021372183892315196, 'max_leaf_nodes': 42, 'max_depth': 4, 'min_samples_leaf': 50, 'l2_regularization': 1.6295724433572687}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  70%|███████   | 141/200 [04:48<01:54,  1.94s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:20,594] Trial 140 finished with value: 0.7139124788517786 and parameters: {'learning_rate': 0.18896683508155934, 'max_leaf_nodes': 69, 'max_depth': 3, 'min_samples_leaf': 69, 'l2_regularization': 0.7082236737913477}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  71%|███████   | 142/200 [04:50<01:44,  1.81s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:22,104] Trial 141 finished with value: 0.7130915238244608 and parameters: {'learning_rate': 0.21577459495825804, 'max_leaf_nodes': 87, 'max_depth': 3, 'min_samples_leaf': 35, 'l2_regularization': 0.8306769746098623}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  72%|███████▏  | 143/200 [04:51<01:32,  1.62s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:23,276] Trial 142 finished with value: 0.7139362423100059 and parameters: {'learning_rate': 0.29743268442100546, 'max_leaf_nodes': 95, 'max_depth': 3, 'min_samples_leaf': 63, 'l2_regularization': 1.756539770574759}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  72%|███████▏  | 144/200 [04:53<01:35,  1.70s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:25,186] Trial 143 finished with value: 0.7137314599733379 and parameters: {'learning_rate': 0.12981286021690028, 'max_leaf_nodes': 78, 'max_depth': 3, 'min_samples_leaf': 40, 'l2_regularization': 1.4427417445076762}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  72%|███████▎  | 145/200 [04:55<01:37,  1.77s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:27,108] Trial 144 finished with value: 0.7136970943310078 and parameters: {'learning_rate': 0.1536699485776724, 'max_leaf_nodes': 102, 'max_depth': 3, 'min_samples_leaf': 58, 'l2_regularization': 1.8165278607643283}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  73%|███████▎  | 146/200 [04:56<01:26,  1.61s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:28,346] Trial 145 finished with value: 0.7127403802200571 and parameters: {'learning_rate': 0.25782064580277997, 'max_leaf_nodes': 63, 'max_depth': 3, 'min_samples_leaf': 53, 'l2_regularization': 0.7671501291346576}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  74%|███████▎  | 147/200 [04:58<01:31,  1.72s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:30,321] Trial 146 finished with value: 0.7130752960146751 and parameters: {'learning_rate': 0.1811327966392733, 'max_leaf_nodes': 59, 'max_depth': 2, 'min_samples_leaf': 46, 'l2_regularization': 1.3679041119429782}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  74%|███████▍  | 148/200 [04:59<01:21,  1.58s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:31,559] Trial 147 finished with value: 0.712091734228879 and parameters: {'learning_rate': 0.1368655418959208, 'max_leaf_nodes': 84, 'max_depth': 9, 'min_samples_leaf': 33, 'l2_regularization': 1.8718472077221056}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  74%|███████▍  | 149/200 [05:00<01:16,  1.51s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:32,903] Trial 148 finished with value: 0.7129509178101496 and parameters: {'learning_rate': 0.21658901518748208, 'max_leaf_nodes': 90, 'max_depth': 3, 'min_samples_leaf': 77, 'l2_regularization': 1.0189020158720743}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  75%|███████▌  | 150/200 [05:02<01:16,  1.53s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:34,481] Trial 149 finished with value: 0.7130528969970816 and parameters: {'learning_rate': 0.16708954031028753, 'max_leaf_nodes': 55, 'max_depth': 4, 'min_samples_leaf': 67, 'l2_regularization': 1.5857550997668617}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  76%|███████▌  | 151/200 [05:03<01:08,  1.40s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:35,583] Trial 150 finished with value: 0.7110560969492326 and parameters: {'learning_rate': 0.26084304663122015, 'max_leaf_nodes': 70, 'max_depth': 6, 'min_samples_leaf': 57, 'l2_regularization': 1.6753565196954527}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  76%|███████▌  | 152/200 [05:05<01:18,  1.64s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:37,778] Trial 151 finished with value: 0.7140030499940482 and parameters: {'learning_rate': 0.16131422769898557, 'max_leaf_nodes': 61, 'max_depth': 3, 'min_samples_leaf': 63, 'l2_regularization': 1.8464194326176353}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  76%|███████▋  | 153/200 [05:07<01:19,  1.68s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:39,571] Trial 152 finished with value: 0.7139657785118071 and parameters: {'learning_rate': 0.19497311449412588, 'max_leaf_nodes': 49, 'max_depth': 3, 'min_samples_leaf': 61, 'l2_regularization': 1.8959280537699492}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  77%|███████▋  | 154/200 [05:09<01:25,  1.86s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:41,824] Trial 153 finished with value: 0.7140100706983261 and parameters: {'learning_rate': 0.10690952309978113, 'max_leaf_nodes': 75, 'max_depth': 3, 'min_samples_leaf': 64, 'l2_regularization': 1.800398539674648}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  78%|███████▊  | 155/200 [05:12<01:28,  1.98s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:44,080] Trial 154 finished with value: 0.7139316142647865 and parameters: {'learning_rate': 0.11906573128095099, 'max_leaf_nodes': 80, 'max_depth': 3, 'min_samples_leaf': 71, 'l2_regularization': 1.7841346749551312}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  78%|███████▊  | 156/200 [05:14<01:32,  2.10s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:46,462] Trial 155 finished with value: 0.712753797893363 and parameters: {'learning_rate': 0.09486387522791109, 'max_leaf_nodes': 74, 'max_depth': 3, 'min_samples_leaf': 52, 'l2_regularization': 1.483385441212923}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  78%|███████▊  | 157/200 [05:16<01:34,  2.19s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:48,867] Trial 156 finished with value: 0.7129214583575424 and parameters: {'learning_rate': 0.10713944513596771, 'max_leaf_nodes': 64, 'max_depth': 3, 'min_samples_leaf': 130, 'l2_regularization': 1.5437276001343063}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  79%|███████▉  | 158/200 [05:18<01:31,  2.17s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:50,990] Trial 157 finished with value: 0.7100380011279235 and parameters: {'learning_rate': 0.08529203484023727, 'max_leaf_nodes': 86, 'max_depth': 2, 'min_samples_leaf': 42, 'l2_regularization': 1.733281713723682}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  80%|███████▉  | 159/200 [05:21<01:28,  2.17s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:53,148] Trial 158 finished with value: 0.7127559738159108 and parameters: {'learning_rate': 0.14152652866369841, 'max_leaf_nodes': 70, 'max_depth': 3, 'min_samples_leaf': 116, 'l2_regularization': 0.9525816535610437}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  80%|████████  | 160/200 [05:22<01:15,  1.89s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:54,397] Trial 159 finished with value: 0.7132126846605653 and parameters: {'learning_rate': 0.2358092676730368, 'max_leaf_nodes': 75, 'max_depth': 4, 'min_samples_leaf': 56, 'l2_regularization': 1.0674441864587447}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  80%|████████  | 161/200 [05:23<01:07,  1.73s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:55,757] Trial 160 finished with value: 0.7132699963287735 and parameters: {'learning_rate': 0.27576452467422996, 'max_leaf_nodes': 81, 'max_depth': 3, 'min_samples_leaf': 50, 'l2_regularization': 1.9384734173352018}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  81%|████████  | 162/200 [05:25<01:09,  1.82s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:57,797] Trial 161 finished with value: 0.7120975206980297 and parameters: {'learning_rate': 0.1668147458661054, 'max_leaf_nodes': 57, 'max_depth': 3, 'min_samples_leaf': 64, 'l2_regularization': 1.8398328647458906}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  82%|████████▏ | 163/200 [05:27<01:03,  1.71s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:24:59,235] Trial 162 finished with value: 0.7141968915532214 and parameters: {'learning_rate': 0.20259925937549125, 'max_leaf_nodes': 67, 'max_depth': 3, 'min_samples_leaf': 65, 'l2_regularization': 1.8230184311055948}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  82%|████████▏ | 164/200 [05:28<00:57,  1.61s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:00,598] Trial 163 finished with value: 0.713231072048236 and parameters: {'learning_rate': 0.21055424560465022, 'max_leaf_nodes': 66, 'max_depth': 3, 'min_samples_leaf': 58, 'l2_regularization': 0.6202746680179999}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  82%|████████▎ | 165/200 [05:30<00:57,  1.64s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:02,319] Trial 164 finished with value: 0.7141145957602069 and parameters: {'learning_rate': 0.18408277566579972, 'max_leaf_nodes': 52, 'max_depth': 3, 'min_samples_leaf': 73, 'l2_regularization': 1.2739453323363934}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  83%|████████▎ | 166/200 [05:32<00:58,  1.71s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:04,185] Trial 165 finished with value: 0.7135904298321412 and parameters: {'learning_rate': 0.1865940016480049, 'max_leaf_nodes': 45, 'max_depth': 3, 'min_samples_leaf': 75, 'l2_regularization': 1.4125330374465292}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  84%|████████▎ | 167/200 [05:33<00:53,  1.63s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:05,644] Trial 166 finished with value: 0.714047772076818 and parameters: {'learning_rate': 0.22251765416641256, 'max_leaf_nodes': 52, 'max_depth': 3, 'min_samples_leaf': 68, 'l2_regularization': 1.2749175880023076}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  84%|████████▍ | 168/200 [05:35<00:55,  1.73s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:07,585] Trial 167 finished with value: 0.7139290330989498 and parameters: {'learning_rate': 0.24113871192269037, 'max_leaf_nodes': 54, 'max_depth': 2, 'min_samples_leaf': 69, 'l2_regularization': 1.335951356958008}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  84%|████████▍ | 169/200 [05:38<01:01,  1.99s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:10,189] Trial 168 finished with value: 0.6077031603916293 and parameters: {'learning_rate': 0.0010494359284788654, 'max_leaf_nodes': 51, 'max_depth': 3, 'min_samples_leaf': 80, 'l2_regularization': 1.188592030312254}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  85%|████████▌ | 170/200 [05:39<00:54,  1.81s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:11,576] Trial 169 finished with value: 0.7136213628240464 and parameters: {'learning_rate': 0.20097049332943945, 'max_leaf_nodes': 41, 'max_depth': 4, 'min_samples_leaf': 73, 'l2_regularization': 1.6575251480597484}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  86%|████████▌ | 171/200 [05:41<00:50,  1.76s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:13,208] Trial 170 finished with value: 0.7132353041446848 and parameters: {'learning_rate': 0.22517382564966845, 'max_leaf_nodes': 34, 'max_depth': 3, 'min_samples_leaf': 67, 'l2_regularization': 1.2450340137328413}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  86%|████████▌ | 172/200 [05:42<00:44,  1.59s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:14,410] Trial 171 finished with value: 0.7130780073363506 and parameters: {'learning_rate': 0.27747566269624285, 'max_leaf_nodes': 63, 'max_depth': 3, 'min_samples_leaf': 62, 'l2_regularization': 1.2808655694627624}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  86%|████████▋ | 173/200 [05:44<00:46,  1.71s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:16,417] Trial 172 finished with value: 0.7135022394293973 and parameters: {'learning_rate': 0.149687238060942, 'max_leaf_nodes': 55, 'max_depth': 3, 'min_samples_leaf': 71, 'l2_regularization': 1.1302737586521245}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  87%|████████▋ | 174/200 [05:46<00:46,  1.79s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:18,386] Trial 173 finished with value: 0.7137635787202363 and parameters: {'learning_rate': 0.18348258770174772, 'max_leaf_nodes': 59, 'max_depth': 3, 'min_samples_leaf': 53, 'l2_regularization': 1.251921452379183}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  88%|████████▊ | 175/200 [05:47<00:40,  1.62s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:19,602] Trial 174 finished with value: 0.7151839233435048 and parameters: {'learning_rate': 0.2515508994244525, 'max_leaf_nodes': 68, 'max_depth': 3, 'min_samples_leaf': 60, 'l2_regularization': 1.554551779113473}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  88%|████████▊ | 176/200 [05:49<00:37,  1.57s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:21,048] Trial 175 finished with value: 0.7131886619283101 and parameters: {'learning_rate': 0.24497603844366772, 'max_leaf_nodes': 48, 'max_depth': 3, 'min_samples_leaf': 60, 'l2_regularization': 1.5574183847458558}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  88%|████████▊ | 177/200 [05:50<00:34,  1.50s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:22,382] Trial 176 finished with value: 0.7131892163549056 and parameters: {'learning_rate': 0.28948471638708834, 'max_leaf_nodes': 69, 'max_depth': 3, 'min_samples_leaf': 66, 'l2_regularization': 1.6032438423532829}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  89%|████████▉ | 178/200 [05:52<00:34,  1.55s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:24,047] Trial 177 finished with value: 0.7133333398102413 and parameters: {'learning_rate': 0.20858878886351687, 'max_leaf_nodes': 67, 'max_depth': 3, 'min_samples_leaf': 57, 'l2_regularization': 1.5166542687146976}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  90%|████████▉ | 179/200 [05:53<00:34,  1.66s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:25,954] Trial 178 finished with value: 0.713960885738149 and parameters: {'learning_rate': 0.29881588814797794, 'max_leaf_nodes': 62, 'max_depth': 2, 'min_samples_leaf': 49, 'l2_regularization': 1.482833072088488}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  90%|█████████ | 180/200 [05:55<00:30,  1.51s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:27,126] Trial 179 finished with value: 0.7131743794985118 and parameters: {'learning_rate': 0.23382362785963468, 'max_leaf_nodes': 57, 'max_depth': 4, 'min_samples_leaf': 60, 'l2_regularization': 1.6444048674890899}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  90%|█████████ | 181/200 [05:56<00:27,  1.44s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:28,393] Trial 180 finished with value: 0.7133260151470491 and parameters: {'learning_rate': 0.2600885340684597, 'max_leaf_nodes': 45, 'max_depth': 3, 'min_samples_leaf': 68, 'l2_regularization': 0.7919198395049482}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  91%|█████████ | 182/200 [05:58<00:29,  1.61s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:30,420] Trial 181 finished with value: 0.7132273970809093 and parameters: {'learning_rate': 0.17222513286456542, 'max_leaf_nodes': 246, 'max_depth': 3, 'min_samples_leaf': 54, 'l2_regularization': 1.4246092362488247}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  92%|█████████▏| 183/200 [06:00<00:29,  1.71s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:32,345] Trial 182 finished with value: 0.7134137944157394 and parameters: {'learning_rate': 0.2019944482501837, 'max_leaf_nodes': 72, 'max_depth': 3, 'min_samples_leaf': 46, 'l2_regularization': 1.3046952425285232}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  92%|█████████▏| 184/200 [06:02<00:27,  1.71s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:34,045] Trial 183 finished with value: 0.7138145929550205 and parameters: {'learning_rate': 0.2134554966197596, 'max_leaf_nodes': 81, 'max_depth': 3, 'min_samples_leaf': 76, 'l2_regularization': 0.8662905863247442}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  92%|█████████▎| 185/200 [06:03<00:26,  1.74s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:35,855] Trial 184 finished with value: 0.7138333352220882 and parameters: {'learning_rate': 0.18475740227189574, 'max_leaf_nodes': 64, 'max_depth': 3, 'min_samples_leaf': 39, 'l2_regularization': 1.5786960672005452}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  93%|█████████▎| 186/200 [06:05<00:22,  1.62s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:37,199] Trial 185 finished with value: 0.7109481351995109 and parameters: {'learning_rate': 0.1287767225587141, 'max_leaf_nodes': 52, 'max_depth': 5, 'min_samples_leaf': 26, 'l2_regularization': 1.904309086418896}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  94%|█████████▎| 187/200 [06:06<00:20,  1.54s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:38,570] Trial 186 finished with value: 0.7128830277941505 and parameters: {'learning_rate': 0.2498231547063513, 'max_leaf_nodes': 76, 'max_depth': 3, 'min_samples_leaf': 56, 'l2_regularization': 0.7313690468957545}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  94%|█████████▍| 188/200 [06:08<00:20,  1.71s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:40,655] Trial 187 finished with value: 0.7134168648013546 and parameters: {'learning_rate': 0.15961625199343468, 'max_leaf_nodes': 97, 'max_depth': 3, 'min_samples_leaf': 64, 'l2_regularization': 1.5180157432742607}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  94%|█████████▍| 189/200 [06:09<00:16,  1.47s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:41,558] Trial 188 finished with value: 0.7118941271247339 and parameters: {'learning_rate': 0.2310600624820018, 'max_leaf_nodes': 67, 'max_depth': 8, 'min_samples_leaf': 60, 'l2_regularization': 1.348838570601534}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  95%|█████████▌| 190/200 [06:10<00:13,  1.39s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:42,760] Trial 189 finished with value: 0.7117773978223445 and parameters: {'learning_rate': 0.14761568762476943, 'max_leaf_nodes': 89, 'max_depth': 6, 'min_samples_leaf': 45, 'l2_regularization': 1.0852063931687652}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  96%|█████████▌| 191/200 [06:12<00:13,  1.51s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:44,563] Trial 190 finished with value: 0.7132791666522593 and parameters: {'learning_rate': 0.18762531067933874, 'max_leaf_nodes': 71, 'max_depth': 3, 'min_samples_leaf': 50, 'l2_regularization': 0.6562307631178469}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  96%|█████████▌| 192/200 [06:13<00:11,  1.43s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:45,801] Trial 191 finished with value: 0.7140476758653855 and parameters: {'learning_rate': 0.2649141749019067, 'max_leaf_nodes': 75, 'max_depth': 3, 'min_samples_leaf': 65, 'l2_regularization': 1.7791039369129067}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  96%|█████████▋| 193/200 [06:15<00:09,  1.41s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:47,154] Trial 192 finished with value: 0.713279044498449 and parameters: {'learning_rate': 0.26227634587671056, 'max_leaf_nodes': 78, 'max_depth': 3, 'min_samples_leaf': 68, 'l2_regularization': 1.754804042252273}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  97%|█████████▋| 194/200 [06:16<00:08,  1.46s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:48,753] Trial 193 finished with value: 0.7136403454083549 and parameters: {'learning_rate': 0.22304182770746742, 'max_leaf_nodes': 83, 'max_depth': 3, 'min_samples_leaf': 72, 'l2_regularization': 1.818819561575813}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  98%|█████████▊| 195/200 [06:18<00:07,  1.49s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:50,304] Trial 194 finished with value: 0.7131556749357781 and parameters: {'learning_rate': 0.299307174369945, 'max_leaf_nodes': 61, 'max_depth': 3, 'min_samples_leaf': 167, 'l2_regularization': 1.6972818788635267}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  98%|█████████▊| 196/200 [06:19<00:06,  1.50s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:51,835] Trial 195 finished with value: 0.7143680997900612 and parameters: {'learning_rate': 0.2686481570442362, 'max_leaf_nodes': 73, 'max_depth': 3, 'min_samples_leaf': 64, 'l2_regularization': 1.7724571233595112}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  98%|█████████▊| 197/200 [06:20<00:04,  1.39s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:52,970] Trial 196 finished with value: 0.7127345336497316 and parameters: {'learning_rate': 0.2629222318316516, 'max_leaf_nodes': 72, 'max_depth': 3, 'min_samples_leaf': 64, 'l2_regularization': 1.7845074607884144}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467:  99%|█████████▉| 198/200 [06:22<00:03,  1.55s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:54,896] Trial 197 finished with value: 0.7133442297735785 and parameters: {'learning_rate': 0.24465122920434557, 'max_leaf_nodes': 67, 'max_depth': 2, 'min_samples_leaf': 58, 'l2_regularization': 1.8774955048996462}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467: 100%|█████████▉| 199/200 [06:24<00:01,  1.59s/it]C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
      "C:\\Users\\alexa\\AppData\\Local\\Temp\\ipykernel_22480\\1941495575.py:13: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:56,580] Trial 198 finished with value: 0.713201231230616 and parameters: {'learning_rate': 0.21327187150536156, 'max_leaf_nodes': 57, 'max_depth': 3, 'min_samples_leaf': 83, 'l2_regularization': 1.7114682757241062}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 117. Best value: 0.715467: 100%|██████████| 200/200 [06:26<00:00,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-07-11 21:25:58,175] Trial 199 finished with value: 0.7149163464428167 and parameters: {'learning_rate': 0.2691377776168708, 'max_leaf_nodes': 51, 'max_depth': 3, 'min_samples_leaf': 54, 'l2_regularization': 1.8350481913219938}. Best is trial 117 with value: 0.715467416975452.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trial</th>\n",
       "      <th>mean_f1</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_leaf_nodes</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>l2_regularization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>0.7155</td>\n",
       "      <td>0.148052</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>1.754657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>174</td>\n",
       "      <td>0.7152</td>\n",
       "      <td>0.251551</td>\n",
       "      <td>68</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>1.554552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>0.7152</td>\n",
       "      <td>0.289965</td>\n",
       "      <td>67</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>0.766773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>0.7149</td>\n",
       "      <td>0.269138</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>1.835048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>0.7146</td>\n",
       "      <td>0.279975</td>\n",
       "      <td>66</td>\n",
       "      <td>3</td>\n",
       "      <td>65</td>\n",
       "      <td>0.763592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     trial  mean_f1  learning_rate  max_leaf_nodes  max_depth  \\\n",
       "117    117   0.7155       0.148052              51          3   \n",
       "174    174   0.7152       0.251551              68          3   \n",
       "33      33   0.7152       0.289965              67          3   \n",
       "199    199   0.7149       0.269138              51          3   \n",
       "34      34   0.7146       0.279975              66          3   \n",
       "\n",
       "     min_samples_leaf  l2_regularization  \n",
       "117                52           1.754657  \n",
       "174                60           1.554552  \n",
       "33                 80           0.766773  \n",
       "199                54           1.835048  \n",
       "34                 65           0.763592  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# 1) Define 5-fold stratified CV (if not already)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "\n",
    "# 2) Objective function for Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"gb__learning_rate\":      trial.suggest_loguniform(\"learning_rate\", 1e-3, 0.3),\n",
    "        \"gb__max_leaf_nodes\":     trial.suggest_int(\"max_leaf_nodes\", 16, 256),\n",
    "        \"gb__max_depth\":          trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"gb__min_samples_leaf\":   trial.suggest_int(\"min_samples_leaf\", 10, 200),\n",
    "        \"gb__l2_regularization\":  trial.suggest_uniform(\"l2_regularization\", 0.0, 2.0)\n",
    "    }\n",
    "    pipelined_model.set_params(**params)\n",
    "    scores = cross_val_score(pipelined_model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
    "    return scores.mean()\n",
    "\n",
    "# 4) Run Optuna study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=200, show_progress_bar=True)\n",
    "\n",
    "# 5) Display top 5 trials\n",
    "df_trials = study.trials_dataframe()\n",
    "df_top5 = df_trials.nlargest(5, \"value\").rename(columns={\n",
    "    \"number\": \"trial\",\n",
    "    \"value\": \"mean_f1\",\n",
    "    \"params_learning_rate\": \"learning_rate\",\n",
    "    \"params_max_leaf_nodes\": \"max_leaf_nodes\",\n",
    "    \"params_max_depth\": \"max_depth\",\n",
    "    \"params_min_samples_leaf\": \"min_samples_leaf\",\n",
    "    \"params_l2_regularization\": \"l2_regularization\"\n",
    "})\n",
    "df_top5[\"mean_f1\"] = df_top5[\"mean_f1\"].round(4)\n",
    "\n",
    "display(df_top5[[\n",
    "    \"trial\", \"mean_f1\",\n",
    "    \"learning_rate\", \"max_leaf_nodes\", \"max_depth\",\n",
    "    \"min_samples_leaf\", \"l2_regularization\"\n",
    "]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 Graded Answer\n",
    "\n",
    "Set `a3` to the mean F1 score of the best model found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a3 = 0.7153                    # replace 0 with your answer, may copy from the displayed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3 = 0.7153\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a3 = {a3:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Final Model Evaluation on Test Set\n",
    "\n",
    "In this problem, you will take the best hyperparameter configuration you found in your earlier experiments (Randomized Search or Optuna) and fully evaluate the resulting model on the test set.\n",
    "\n",
    "**Background:**\n",
    "When performing hyperparameter tuning, we typically optimize for a single metric (e.g., F1). However, before deployment, it is essential to check **all relevant metrics** on the final test set to understand the model’s behavior in a balanced way.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Take the best hyperparameters you found in Problems 2 or 3 and apply them to your `pipelined_model`.\n",
    "2. Re-train this final tuned model on the **entire training set** (not just the folds).\n",
    "3. Evaluate the final model on the heldout **test set**, reporting the following metrics:\n",
    "\n",
    "   * Precision\n",
    "   * Recall\n",
    "   * F1 score\n",
    "   * Balanced accuracy\n",
    "4. Use `classification_report` **on the test set** to print precision, recall, and F1 score, and use `balanced_accuracy_score` separately to calculate and print balanced accuracy.\n",
    "5. Answer the graded questions.\n",
    "\n",
    "**Note:** We evaluate the metrics on the test set because it was never seen during training or hyperparameter tuning. This gives us an unbiased estimate of how the model will perform on truly unseen data. Evaluating on the training set would be misleading, because the model has already learned from that data and could appear artificially good.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Classification Report on Test Set ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9514    0.8247    0.8835      7431\n",
      "           1     0.6085    0.8661    0.7148      2338\n",
      "\n",
      "    accuracy                         0.8346      9769\n",
      "   macro avg     0.7799    0.8454    0.7991      9769\n",
      "weighted avg     0.8693    0.8346    0.8431      9769\n",
      "\n",
      "Balanced Accuracy on Test Set: 0.8454\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# 1) Rebuild the preprocessing + classifier pipeline with best params\n",
    "enc = OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\",\n",
    "    unknown_value=-1,\n",
    "    encoded_missing_value=-2,\n",
    "    dtype=np.int64\n",
    ")\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"cat\", enc, cat_cols),\n",
    "    (\"num\", \"passthrough\", num_cols),\n",
    "])\n",
    "\n",
    "best_hyperparams = {\n",
    "    \"learning_rate\":      0.292903,\n",
    "    \"max_leaf_nodes\":     44,\n",
    "    \"max_depth\":          2,\n",
    "    \"min_samples_leaf\":   14,\n",
    "    \"l2_regularization\":  1.187083\n",
    "}\n",
    "\n",
    "final_clf = HistGradientBoostingClassifier(\n",
    "    **best_hyperparams,\n",
    "    max_bins=255,\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=20,\n",
    "    validation_fraction=0.2,\n",
    "    tol=1e-7,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=random_seed,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "final_pipe = Pipeline([\n",
    "    (\"prep\", preprocess),\n",
    "    (\"gb\",   final_clf)\n",
    "])\n",
    "\n",
    "# 2) Train on the entire training set\n",
    "final_pipe.fit(X_train, y_train)\n",
    "\n",
    "# 3) Predict on test set\n",
    "y_pred = final_pipe.predict(X_test)\n",
    "\n",
    "# 4) Report metrics\n",
    "print(\"=== Classification Report on Test Set ===\")\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "print(f\"Balanced Accuracy on Test Set: {bal_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4 Graded Questions\n",
    "\n",
    "- Set `a4a` to the balanced accuracy score of the best model.\n",
    "- Set `a4b` to the macro average precision of this model.\n",
    "- Set `a4c` to the macro average recall score of the this model.\n",
    "\n",
    "**Note:** Macro average takes the mean of each class’s precision/recall without considering how many samples each class has, which is appropriate for a balanced evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a4a = 0.8454                     # replace 0 with your answer, use variable or expression from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4a = 0.8454\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a4a = {a4a:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a4b = 0.7799                  # replace 0 with your answer, may copy from the displayed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4b = 0.7799\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a4b = {a4b:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a4c = 0.8454                   # replace 0 with your answer, may copy from the displayed results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4c = 0.8454\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a4c = {a4c:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Understanding Precision, Recall, F1, and Balanced Accuracy\n",
    "\n",
    "**Tutorial**\n",
    "\n",
    "In binary classification, you will often evaluate these key metrics:\n",
    "\n",
    "* **Precision**: *Of all the positive predictions the model made, how many were actually correct?*\n",
    "\n",
    "  * High precision = few false positives\n",
    "  * Low precision = many false positives\n",
    "\n",
    "* **Recall**: *Of all the actual positive cases, how many did the model correctly identify?*\n",
    "\n",
    "  * High recall = few false negatives\n",
    "  * Low recall = many false negatives\n",
    "\n",
    "* **F1 score**: The harmonic mean of precision and recall, which balances them in a single measure.\n",
    "\n",
    "  * F1 is **highest** when precision and recall are both high and similar in value.\n",
    "  * If precision and recall are unbalanced, F1 will drop to reflect that imbalance.\n",
    "\n",
    "* **Balanced accuracy**: The average of recall across both classes (positive and negative).\n",
    "\n",
    "  * It ensures the classifier is performing reasonably well on *both* groups, correcting for class imbalance.\n",
    "  * Balanced accuracy is especially important if the classes are very unequal in size.\n",
    "\n",
    "**Typical trade-offs to remember:**\n",
    "\n",
    "* **Higher recall, lower precision**: the model finds most true positives but also mislabels some negatives as positives\n",
    "* **Higher precision, lower recall**: the model is strict about positive predictions, but misses some true positives\n",
    "* **Balanced precision and recall (good F1)**: a practical compromise\n",
    "* **Balanced accuracy**: checks fairness across both classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Problem 5 Graded Question (multiple choice)\n",
    "\n",
    "A bank uses your model to identify customers earning over $50K for a premium product invitation. Based on your final test set evaluation, including macro-averaged precision and recall, which of the following best describes what might happen?\n",
    "\n",
    "(1) The bank will miss some eligible high-income customers, but will avoid marketing mistakes by sending invitations only to those it is  confident about.\n",
    "\n",
    "(2) The bank will successfully reach most high-income customers, but will also waste resources sending invitations to some low-income customers.\n",
    "\n",
    "(3) The bank will perfectly identify all high-income and low-income customers, resulting in no wasted invitations and no missed opportunities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Your answer here\n",
    "\n",
    "a5 = 2                     # replace 0 with one of 1, 2, or 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a5 = 2\n"
     ]
    }
   ],
   "source": [
    "# DO NOT change this cell in any way\n",
    "\n",
    "print(f'a5 = {a5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix One: Feature Engineering\n",
    "\n",
    "Here are some practical feature-engineering tweaks worth considering (beyond simply ordinal-encoding the categoricals)\n",
    "\n",
    "| Feature(s)                                                           | Why the tweak can help                                                                                                                                                     | How to do it (quick version)                                                                                                                                                    | Keep / drop?      |\n",
    "| -------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------- |\n",
    "| **`fnlwgt`**                                                         | Survey sampling weight, not a predictor. Leaving it in often lets the model “cheat.”                                                                                       | `df = df.drop(columns=[\"fnlwgt\"])`                                                                                                                                              | **Drop**          |\n",
    "| **`education` *vs.* `education-num`**                                | They encode the **same** information twice (categorical label and its ordinal rank). Keeping both is redundant and can cause leakage of a perfectly predictive feature.    | Usually keep **only one**. For tree models `education-num` is simplest: `df = df.drop(columns=[\"education\"])`                                                                   | **Drop one**      |\n",
    "| **`capital-gain`, `capital-loss`**                                   | Highly skewed; most values are zero with a long upper tail. The sign (gain vs. loss) matters, but treating them separately wastes a feature slot.                          | 1) Combine: `df[\"capital_net\"] = df[\"capital-gain\"] - df[\"capital-loss\"]`; 2) Log-transform to reduce skew: `df[\"capital_net_log\"] = np.log1p(df[\"capital_net\"].clip(lower=0))` | Replace originals |\n",
    "| **`age`, `hours-per-week`**                                          | Continuous but with natural plateaus—trees handle splits fine, yet log or square-root scaling can soften extreme values; bucketing makes partial-dependence plots clearer. | Simple bucket: `df[\"age_bin\"] = pd.cut(df[\"age\"], bins=[16,25,35,45,55,65,90])` (optional)                                                                                      | Optional          |\n",
    "| **Missing categories** (`workclass`, `occupation`, `native-country`) | HGB handles `-1`/`-2` codes fine, but you may want *explicit* “Missing” bucket for interpretability.                                                                       | Use `encoded_missing_value=-2` during encoding.                                                                                                            | Keep as is        |\n",
    "| **Rare categories in `native-country`**                              | Hundreds of low-frequency countries dilute signal; grouping boosts stability.                                                                                              | Map infrequent categories to “Other”:                                                                                                                                           |                   |\n",
    "\n",
    "\n",
    "#### Minimum set of tweaks (good baseline, low effort)\n",
    "\n",
    "1. **Drop `fnlwgt`.**  \n",
    "2. **Keep `education-num`, drop `education`.**  \n",
    "3. **Combine `capital-gain` and `capital-loss` into `capital_net`** (optionally add a log-scaled version).  \n",
    "4. Leave other numeric/categorical features as is; your histogram-GBDT will cope.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
